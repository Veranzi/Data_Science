{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1E1yY4VZcJDI3u3e239kxoL_IUPXSQlRk",
      "authorship_tag": "ABX9TyO0mjYP8zKQS7Co7raNVGVl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Veranzi/Data_Science/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT LIBRARIES"
      ],
      "metadata": {
        "id": "nUznSWOnUzMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nrclex\n"
      ],
      "metadata": {
        "id": "In4uZOYaVb7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIPUkIaiSyJw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nrclex import NRCLex\n",
        "\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from scipy.stats import norm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/sentimentdataset.csv\")"
      ],
      "metadata": {
        "id": "Kqc6_vr4U1_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "JPzNPHJmVD2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "956Kp5MQVuDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "gHbrQJwSVz7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "ITtDqvWeV5Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA CLEANING"
      ],
      "metadata": {
        "id": "rVQp6taDWGhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "UVGI9uJdWABj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df['Sentiment']\n",
        "df1\n"
      ],
      "metadata": {
        "id": "HlGMifJN8b2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVE COLUMNS NOT NEEDED"
      ],
      "metadata": {
        "id": "2rvXZpqTWppt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "YlpaK0PgWWZJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "eMoHkPeVjNOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DO AWAY WITH GAPS IN \"OBJECT DATATYPES\""
      ],
      "metadata": {
        "id": "PjgzJ0IoXoTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select_dtypes(include=[object])\n",
        "\n",
        "list(df.columns)"
      ],
      "metadata": {
        "id": "5n0vgGc6XR3O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To remove leading and trailing whitespaces from string columns"
      ],
      "metadata": {
        "id": "sxRCzltWYvyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[df.columns] = df[df.columns].apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "df\n"
      ],
      "metadata": {
        "id": "ujlV7byCX0_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handling duplicates"
      ],
      "metadata": {
        "id": "LE0h6bBCZCoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated()"
      ],
      "metadata": {
        "id": "2jilReYjY09z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The number of duplicated rows"
      ],
      "metadata": {
        "id": "Eb9BuFAraZZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len_duplicated = len(df[df.duplicated(subset=['Text', 'Timestamp', 'Platform'])])\n"
      ],
      "metadata": {
        "id": "DsJT25lXZMLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count unique rows based on 'Text' and 'Platform' columns only"
      ],
      "metadata": {
        "id": "ITpXdjjka6OS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_rows = len(df) - len(df[df.duplicated(subset=['Text', 'Timestamp','Platform'])])\n",
        "unique_rows"
      ],
      "metadata": {
        "id": "HQOsBdPxajsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rename pudlicated entries and save to a new dataframe"
      ],
      "metadata": {
        "id": "g82vyZ4_bZwj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "no_duplicated = df.drop_duplicates(subset=['Text','Timestamp', 'Platform'], keep='first')\n",
        "no_duplicated"
      ],
      "metadata": {
        "id": "e1r4tYQ-bB3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find unique values in platform"
      ],
      "metadata": {
        "id": "HVejRWN8cNk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_duplicated['Platform'].unique()\n"
      ],
      "metadata": {
        "id": "K9quwtaEcRga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter = no_duplicated[no_duplicated[\"Platform\"] == 'Twitter']\n",
        "instagram = no_duplicated[no_duplicated[\"Platform\"] == 'Instagram']\n",
        "facebook = no_duplicated[no_duplicated[\"Platform\"] == 'Facebook']"
      ],
      "metadata": {
        "id": "IRNztLyBbbFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_duplicated"
      ],
      "metadata": {
        "id": "kCNCWt8_iANh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "WGokolKcdlIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data based on platform"
      ],
      "metadata": {
        "id": "pccGcuBBeda3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Counts from each platform DataFrame\n",
        "counts = [twitter['Text'].count(), instagram['Text'].count(), facebook['Text'].count()]\n",
        "\n",
        "# Platform names for x-axis labels\n",
        "platforms = ['Twitter', 'Instagram', 'Facebook']\n",
        "\n",
        "# Colors for bars\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "# Plotting\n",
        "plt.bar(platforms, counts, color=colors)\n",
        "plt.ylabel('Counts')\n",
        "plt.xlabel('Platforms')\n",
        "plt.title('Counts of Text Entries by Platform')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pZce6Cu6cwXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "JgcFNYG1hyhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(twitter.groupby(['Timestamp']).Platform.count(), color= \"#6699CC\", marker ='o', label='Twitter')\n",
        "plt.plot(instagram.groupby(['Timestamp']).Platform.count(), color= \"#CC6677\", marker ='o', label='Instagram')\n",
        "plt.plot(facebook.groupby(['Timestamp']).Platform.count(), color= \"#997700\", marker ='o', label='Facebook')\n",
        "plt.xlabel('Timestamp')\n",
        "plt.ylabel('Counts')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "QtqPMaYyjicM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counts from each platform DataFrame\n",
        "counts = [twitter['Sentiment'].count(), instagram['Sentiment'].count(), facebook['Sentiment'].count()]\n",
        "\n",
        "# Platform names for x-axis labels\n",
        "platforms = ['Twitter', 'Instagram', 'Facebook']\n",
        "\n",
        "# Colors for bars\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
        "\n",
        "# Plotting\n",
        "plt.bar(platforms, counts, color=colors)\n",
        "plt.ylabel('Counts')\n",
        "plt.xlabel('Platforms')\n",
        "plt.title('Counts of Sentiment Entries by Platform')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sRn-569IjuWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.displot(data=no_duplicated[['Platform','Country']], x=\"Platform\", hue=\"Country\",\n",
        "            palette = [\"#6699CC\", '#CC6677', '#997700'],\n",
        "            alpha=0.3,\n",
        "           # multiple='dodge',\n",
        "           # multiple='stack',\n",
        "            kde=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wM3Gjbz_j97h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_duplicated['Sentiment'].value_counts().nlargest(10).plot(kind='bar')\n",
        "plt.title('Top 10 Sentiments based on Text')\n",
        "plt.xlabel('Sentiment')\n",
        "plt.ylabel('text')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UsrZz7SHreUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_duplicated['Platform'].value_counts().plot(kind='pie', autopct='%1.5f%%')\n",
        "plt.title('Percentages of Platforms')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qYGbH--zrrzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_duplicated['Country'].value_counts().nlargest(10).plot(kind='bar')\n",
        "plt.title('Based on Country')\n",
        "plt.xlabel('Country')\n",
        "plt.ylabel('Count')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DukfagTJr6we"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "LsOMPgtkncJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "for i in no_duplicated.index:\n",
        "    text = no_duplicated.loc[i, \"Text\"].lower()\n",
        "    emotion = NRCLex(text)\n",
        "    positive_score = emotion.affect_frequencies['positive']\n",
        "    negative_score = emotion.affect_frequencies['negative']\n",
        "    #print(\"positive_score\", positive_score, \"negative_score\", negative_score)\n",
        "    if positive_score > negative_score:\n",
        "        no_duplicated.loc[i, \"Sentiment_NRC\"] = \"Positive\"\n",
        "    elif positive_score == negative_score:\n",
        "        no_duplicated.loc[i, \"Sentiment_NRC\"] = \"Neutral\"\n",
        "    else:\n",
        "        no_duplicated.loc[i, \"Sentiment_NRC\"] = \"Negative\""
      ],
      "metadata": {
        "id": "mIzsMK5UkbWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UBB2R4qOoH6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "yiEn_KUUoIhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract unique sentiments and map of sentiment to unique label.\n",
        "Add a new column with numeric labels based on the mapping\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h8YIdX2XCIOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "unique_sentiments = no_duplicated['Sentiment'].unique()\n",
        "\n",
        "sentiment_label_map = {sentiment: idx for idx, sentiment in enumerate(unique_sentiments)}\n",
        "\n",
        "\n",
        "no_duplicated['Label'] = no_duplicated['Sentiment'].map(sentiment_label_map)\n",
        "\n",
        "# Print\n",
        "print(no_duplicated[['Text', 'Sentiment', 'Label']])"
      ],
      "metadata": {
        "id": "hCZe7DZaAJWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data into train and test sets"
      ],
      "metadata": {
        "id": "OOsSwCG4BBH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(no_duplicated['Text'], no_duplicated['Label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Llz2O05VnIcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create TF-IDF vectorizer"
      ],
      "metadata": {
        "id": "0XfFIr6KBMBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "JPhrpfqYnlvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeClassifier"
      ],
      "metadata": {
        "id": "K9lvzu4zBOMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train_tfidf, y_train)\n",
        "tfidf_transformer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "t9aL919WqIqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict"
      ],
      "metadata": {
        "id": "3b1fSPyDBR6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = dt_model.predict(X_test_tfidf)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "G919_pQKoWZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataframe prediction"
      ],
      "metadata": {
        "id": "AJTH1IWLBa4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.DataFrame({'Predicted Values': y_pred})\n",
        "\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "KWdi3bwmodro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "report = classification_report(y_test, y_pred, zero_division=1)"
      ],
      "metadata": {
        "id": "jbwPJMAro6Re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_pred and y_true are the predicted and true values, respectively, calculate and print accuracy."
      ],
      "metadata": {
        "id": "Y9mxfGA1CpXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = dt_model.predict(X_test_tfidf)\n",
        "y_true = y_test\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "A7KdGu5TpFB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_classification_report(report):\n",
        "    lines = report.split(\"\\n\")\n",
        "    lines = [line.strip() for line in lines if line.strip\n",
        "            ()]\n",
        "    class_names = []\n",
        "    metrics = []\n",
        "    for line in lines[2:]:\n",
        "        parts = line.split()\n",
        "        if len(parts) > 1 and parts[0].strip() != 'accuracy':\n",
        "            class_name = ' '.join(parts[:-4])\n",
        "            class_names.append(class_name)\n",
        "            class_metrics = [float(part) for part in parts[-4:] if part != 'support']\n",
        "            metrics.append(class_metrics)\n",
        "\n",
        "    return class_names, metrics\n",
        "\n",
        "class_names, metrics = parse_classification_report(report)"
      ],
      "metadata": {
        "id": "5OGI_ggWpXvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_names = ['precision', 'recall', 'f1-score']\n",
        "metric_dict = {metric: [m[i] for m in metrics] for i, metric in enumerate(metric_names)}"
      ],
      "metadata": {
        "id": "ErwgZP3zq0WV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the classification report metrics"
      ],
      "metadata": {
        "id": "IuIfR8c6CCXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name, values in metric_dict.items():\n",
        "    plt.barh(class_names, values, label=metric_name)\n",
        "\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Performance Metrics')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gOe4rI_Kq78b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to predict sentiment and label from input text"
      ],
      "metadata": {
        "id": "ir03FpaXBiPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def predict_sentiment(input_text):\n",
        "\n",
        "    # Transform input text using the fitted TF-IDF vectorizer\n",
        "    input_text_tfidf = tfidf_vectorizer.transform([input_text])\n",
        "\n",
        "\n",
        "    predicted_label = dt_model.predict(input_text_tfidf)[0]\n",
        "\n",
        "    # Map predicted label back to sentiment\n",
        "\n",
        "    predicted_sentiment = unique_sentiments[predicted_label]\n",
        "\n",
        "    return predicted_sentiment, predicted_label\n"
      ],
      "metadata": {
        "id": "yKIDR2T3-BIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pratical example by prompting a user."
      ],
      "metadata": {
        "id": "4cxbw4WTBshQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "user_input = input(\"Enter a text to be analyzed: \")\n",
        "predicted_sentiment, predicted_label = predict_sentiment(user_input)\n",
        "\n",
        "print(f\"Predicted Sentiment: {predicted_sentiment}\")\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ],
      "metadata": {
        "id": "2kruelpABqGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sBNEcffpDjPP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}